{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "可选: 数据并行\n",
    "==========================\n",
    "**作者**: `Sung Kim <https://github.com/hunkim>`_ 和 `Jenny Kang <https://github.com/jennykang>`_\n",
    "\n",
    "在这个教程中, 我们将会学习如何在多个GPU上使用 ``DataParallel`` .\n",
    "\n",
    "在 PyTorch 中使用 GPU 是一件很容易的事情.你可以像下面这样轻松的将一个模型分配到一个 GPU 上.\n",
    "\n",
    "\n",
    "`model.gpu()`\n",
    "\n",
    "随后, 你可以将你的所有张量拷贝到上面的GPU:\n",
    "\n",
    "\n",
    "`mytensor = my_tensor.gpu()`\n",
    "\n",
    "此处请注意: 如果只是调用 ``mytensor.gpu()`` 是不会将张量拷贝到 GPU 的.你需要将它赋给一个\n",
    "新的张量, 这个张量就能在 GPU 上使用了.\n",
    "\n",
    "在多个 GPU 上运行前向、反向传播是一件很自然的事情, 然而,  PyTorch 默认情况下只会用到一个GPU, \n",
    "可以通过使用 ``DataParallel`` 使你的模型并行运行, 在多个GPU上运行这些操作也将变得非常简单:\n",
    "\n",
    "`model = nn.DataParallel(model)`\n",
    "\n",
    "这是教程的核心内容, 我们将在随后进行详细讲解\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入和参数\n",
    "----------------------\n",
    "\n",
    "导入PyTorch模块和参数定义\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 参数和数据加载\n",
    "input_size = 5\n",
    "output_size = 2\n",
    "\n",
    "batch_size = 30\n",
    "data_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "伪数据集\n",
    "-------------\n",
    "\n",
    "只需要实现 getitem 就可以轻松的生成一个（随机）伪数据集, 如下代码所示: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, size, length):\n",
    "        self.len = length\n",
    "        self.data = torch.randn(length, size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "rand_loader = DataLoader(dataset=RandomDataset(input_size, 100),\n",
    "                         batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单模型\n",
    "------------\n",
    "\n",
    "在下面的示例中, 我们的模型只需要一个输入并且完成一个线性操作, 最后得\n",
    "到一个输出.当然, 你可以在任意模型 (CNN,RNN,Capsule Net等) 运用  ``DataParallel``  \n",
    "\n",
    "我们在模型中设置了打印指令来监控输入和输出的张量大小, 请注意批数据次序为0时的输出.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    # Our model\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.fc(input)\n",
    "        print(\"  In Model: input size\", input.size(), \n",
    "              \"output size\", output.size())\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建模型和 DataParallel\n",
    "-----------------------------\n",
    "\n",
    "这是本教程的核心部分. 首先, 我们需要生成一个模型的实例并且检测我们是否拥有多个\n",
    "GPU.如果有多个GPU , 我们可以使用 ``nn.DataParallel`` 来包装我们的模型, 然后我们\n",
    "就可以将我们的模型通过 ``model.gpu()`` 施加于这些GPU上.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7L"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Let's use\", 7L, 'GPUs!')\n"
     ]
    }
   ],
   "source": [
    "model = Model(input_size, output_size)\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = nn.DataParallel(model)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行模型\n",
    "-------------\n",
    "\n",
    "现在我们可以看到输入和输出张量的大小了.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))\n",
      "('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))\n",
      "\n",
      "('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))\n",
      "('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))\n",
      "('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))\n",
      "00000\n",
      "('Outside: input size', torch.Size([30, 5]), 'output_size', torch.Size([30, 2]))\n",
      "11111\n",
      "('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))\n",
      "('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))\n",
      "('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))\n",
      "('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))\n",
      "('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))\n",
      "('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))\n",
      "00000\n",
      "('Outside: input size', torch.Size([30, 5]), 'output_size', torch.Size([30, 2]))\n",
      "11111\n",
      "('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))\n",
      "('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))\n",
      "\n",
      "\n",
      "('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))\n",
      "('  In Model: input size', torch.Size([5, 5]), 'output size', torch.Size([5, 2]))\n",
      "00000\n",
      "('Outside: input size', torch.Size([30, 5]), 'output_size', torch.Size([30, 2]))\n",
      "11111\n",
      "('  In Model: input size', torch.Size([2, 5]), 'output size', torch.Size([2, 2]))\n",
      "('  In Model: input size', torch.Size([2, 5]), 'output size', torch.Size([2, 2]))\n",
      "('  In Model: input size', torch.Size([2, 5]), 'output size', torch.Size([2, 2]))\n",
      " ('  In Model: input size', torch.Size([2, 5]), 'output size', torch.Size([2, 2]))\n",
      "('  In Model: input size', torch.Size([2, 5]), 'output size', torch.Size([2, 2]))\n",
      "00000\n",
      "('Outside: input size', torch.Size([10, 5]), 'output_size', torch.Size([10, 2]))\n",
      "11111\n"
     ]
    }
   ],
   "source": [
    "for data in rand_loader:\n",
    "    if torch.cuda.is_available():\n",
    "        input_var = Variable(data.cuda())\n",
    "    else:\n",
    "        input_var = Variable(data)\n",
    "    output = model(input_var)\n",
    "    print('00000')\n",
    "    print(\"Outside: input size\", input_var.size(), \"output_size\", output.size())\n",
    "    print('11111')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果\n",
    "-------\n",
    "\n",
    "当我们将输入设置为30批, 模型也产生了30批的输出.但是当我们使用多个GPU, 然后你\n",
    "会得到类似下面这样的输出.\n",
    "\n",
    "### 2 GPUs\n",
    "\n",
    "\n",
    "如果有2个GPU, 我们将会看到这样的结果:\n",
    "\n",
    "\n",
    "    # on 2 GPUs\n",
    "    Let's use 2 GPUs!\n",
    "        In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
    "        In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
    "    Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
    "        In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
    "        In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
    "    Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
    "        In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
    "        In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
    "    Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
    "        In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])\n",
    "        In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])\n",
    "    Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])\n",
    "\n",
    "### 3 GPUs\n",
    "\n",
    "\n",
    "如果有3个GPU, 我们将会看到这样的结果:\n",
    "\n",
    "    Let's use 3 GPUs!\n",
    "        In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])\n",
    "        In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])\n",
    "        In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])\n",
    "    Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
    "        In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])\n",
    "        In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])\n",
    "        In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])\n",
    "    Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
    "        In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])\n",
    "        In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])\n",
    "        In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])\n",
    "    Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])\n",
    "    Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])\n",
    "\n",
    "### 8 GPUs\n",
    "\n",
    "\n",
    "如果有8个GPU, 我们将会看到这样的结果:\n",
    "\n",
    "    Let's use 8 GPUs!\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "    Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "    Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])\n",
    "        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])\n",
    "    Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
    "        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])\n",
    "        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])\n",
    "        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])\n",
    "        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])\n",
    "        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])\n",
    "    Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结\n",
    "-------\n",
    "\n",
    "DataParallel 自动地将数据分割并且将任务送入多个GPU上的多个模型中进行处理.\n",
    "在每个模型完成任务后,  DataParallel 采集和合并所有结果, 并将最后的结果呈现给你.\n",
    "\n",
    "想了解更多信息, 请点击:\n",
    "http://pytorch.org/tutorials/beginner/former\\_torchies/parallelism\\_tutorial.html.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch 多GPU训练\n",
    "转载：[pytorch 多GPU训练](https://blog.csdn.net/jacke121/article/details/80605205)\n",
    "\n",
    "pytorch多GPU最终还是没搞通，可用的部分是前向计算，back propagation会出错，当时运行通过，也不太确定是如何通过了的。目前是这样，有机会再来补充\n",
    "\n",
    "pytorch支持多GPU训练，官方文档（pytorch 0.30）给了一些说明：pytorch数据并行，但遗憾的是给出的说明并不详细。不过说的还是蛮清楚的，建议使用`DataParallel`。\n",
    "\n",
    "pytorch使用多GPU训练的时候要考虑的主要的不过是前向计算和后向计算两个部分。\n",
    "## 前向计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net() #Net是自定义的一个网络结构类  \n",
    "device_ids = [2, 4, 5]  \n",
    "cudnn.benchmark = True  \n",
    "net = net.cuda(device_ids[0])  \n",
    "net = nn.DataParallel(net, device_ids=device_ids) #使用dataParallel重新包装一下  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataparallel`会把输入数据以某个轴（默认是 0 轴）将数据分开成平均几份，所以要保证batch size每一个批中的图片数目是相对于用到的GPU可除的。等调用`net`结束后，将再次把分开运算得到的数据自动组合在一起。\n",
    "## 后向计算：\n",
    "神经网络还需要后向计算以更新梯度，因为`grad_fn`在`dataparallel`中，所以也要将更新梯度的方法放入到`dataparallel`中去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2  \n",
    "momentum = 0.9  \n",
    "weight_decay = 1e-3  \n",
    "param = get_param(net, lr)  \n",
    "optimizer = optim.SGD(param, momentum=momentum, weight_decay=weight_decay) #准备pytorch中的随机梯度下降方法  \n",
    "loss = nn.MSEloss()   \n",
    "optimizer = nn.DataParallel(optimizer, device_ids=device_ids) #将optimizer放入dataparallel中。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataParallel的使用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Variable(img, requires_grad=True).cuda(device_ids[0])  # 输入图片数据  \n",
    "gt = Variable(gt_heatmap).cuda(device_ids[0]) #ground truth  \n",
    "  \n",
    "predicted = net(img) # net是DataParallel对象,img 作为输入会将分为3份（bachsize/3），等3个并行计算结束后再以该轴组合再一起，predicted和img的shape是一样的。  \n",
    "l = loss(gt, predicted)   \n",
    "  \n",
    "# compute gradient and do SGD step  \n",
    "optimizer.zero_grad()   \n",
    "l.backward() #在这儿使用optimizer的相应的对象。  \n",
    "optimizer.module.step() #因为它在DataParallel里面，所以要先变成普通的nn.SGD对象，然后才能调用该类的梯度更新方法。类似的，还有其他的一些需要注意的地方，看下面：  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相应的学习率更新的方法：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_lr in optimizer.module.param_groups: #同样是要加module  \n",
    "    param_lr['lr'] /= 2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载保存的网络参数：\n",
    "\n",
    "加载保存的网络参数时也要注意，因为所有的保存的参数对应的关键字都加了`module`。可以像下面这样使用序号的方式重新加载所保存的网络参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = net.state_dict()  \n",
    "vgg_19_key = list(vgg_19.keys())  \n",
    "model_key = list(model_dict.keys())  \n",
    "from collections import OrderedDict  \n",
    "vgg_dict = OrderedDict()  \n",
    "for i in range(param_num):  \n",
    "    vgg_dict[model_key[i]] = vgg_19[vgg_19_key[i]]  \n",
    "model_dict.update(vgg_dict)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以简单的去掉`OrderedDict`关键字多出的`module`，像这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, value in saved_state.items():  \n",
    "    name = '.'.join(item.split('.')[1:])  \n",
    "    trans_param[name] = value  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "像这样就可以实现pytorch多GPU训练网络了。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
